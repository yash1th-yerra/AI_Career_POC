{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17cb09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import pdfplumber\n",
    "import docx2txt\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139e825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env for API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3295eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not api_key:\n",
    "    raise ValueError(\"‚ùå GOOGLE_API_KEY not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6196d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759853245.293862    9971 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemini 2.5 Flash LLM with safe optimizations (maintains consistency)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.2,  # Restore original temperature for consistency\n",
    "    api_key=api_key,\n",
    "    max_output_tokens=4096,  # Set explicit limit for faster response\n",
    "    max_retries=2,  # Keep reasonable retries for reliability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a109c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_file(file_path: str, file_type: str) -> str:\n",
    "    \"\"\"Extract text from PDF or DOCX resume.\"\"\"\n",
    "    if file_type.lower() == \"pdf\":\n",
    "        text_parts = []\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            max_pages = min(2, len(pdf.pages))\n",
    "            for i in range(max_pages):\n",
    "                text_parts.append(pdf.pages[i].extract_text() or \"\")\n",
    "        text = \"\\n\".join(text_parts)\n",
    "    elif file_type.lower() == \"docx\":\n",
    "        text = docx2txt.process(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "    # Optional cleaning\n",
    "    text = text.replace('\\n', ' ').replace('\\t', ' ').strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9814675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Unified Resume Extraction with JSON Output (Fixed Parser Issue)\n",
    "import json\n",
    "\n",
    "# Create a LangChain prompt with direct JSON output\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert Resume Intelligence Agent that extracts structured data and evaluates resumes for ATS compatibility.\n",
    "\n",
    "Analyze the following resume text and return ONLY a valid JSON object with these exact keys:\n",
    "\n",
    "{{\n",
    "  \"name\": \"\",\n",
    "  \"location\": \"\",\n",
    "  \"summary\": \"\",\n",
    "  \"skills\": [],\n",
    "  \"extra_skills\": [],\n",
    "  \"work_experience\": [],\n",
    "  \"projects\": [],\n",
    "  \"certifications\": [],\n",
    "  \"education\": [],\n",
    "  \"ats_feedback\": {{\n",
    "    \"score\": 0,\n",
    "    \"summary\": \"\",\n",
    "    \"strengths\": [],\n",
    "    \"improvements\": []\n",
    "  }}\n",
    "}}\n",
    "\n",
    "CRITICAL EXTRACTION RULES FOR ALL SECTIONS:\n",
    "\n",
    "1. **NAME**: Extract the full name exactly as written, using the most prominent name (usually at the top).\n",
    "\n",
    "2. **LOCATION**: Extract specific city and country from contact info, address, or personal details. Format as \"City, Country\" (e.g., \"Chennai, India\", \"Bangalore, India\"). If no city is specified, use \" Country\".\n",
    "\n",
    "3. **SUMMARY**: Look for sections titled \"Summary\", \"Objective\", \"Profile\", \"About Me\", \"Career Summary\". Extract complete professional summary.\n",
    "\n",
    "4. **SKILLS**: Extract skills ONLY from dedicated \"Skills\", \"Technical Skills\", \"Core Skills\", \"Programming Languages\", or similar sections:\n",
    "   - ONLY include skills explicitly listed in a dedicated skills section\n",
    "   - Programming languages, frameworks, tools, technologies mentioned in skills section\n",
    "   - Return as array of individual skills from the skills section only\n",
    "\n",
    "5. **EXTRA_SKILLS**: Extract additional skills mentioned in other contexts:\n",
    "   - Skills mentioned in work experience descriptions\n",
    "   - Technologies used in projects\n",
    "   - Skills mentioned in certifications or education\n",
    "   - Any other skills not in the main skills section\n",
    "   - Return as array of individual skills from non-skills sections\n",
    "\n",
    "6. **WORK_EXPERIENCE**: Extract each position with:\n",
    "   - Job title, company, duration, location\n",
    "   - Key responsibilities and achievements\n",
    "   - Format as structured objects with consistent fields\n",
    "\n",
    "7. **PROJECTS**: Extract personal/academic projects with:\n",
    "   - Project name, duration, technologies used\n",
    "   - Brief description and key features\n",
    "   - Any notable achievements or results\n",
    "\n",
    "8. **CERTIFICATIONS**: Extract all certifications with:\n",
    "   - Certification name, issuing organization, year\n",
    "   - Include online courses, professional certifications\n",
    "\n",
    "9. **EDUCATION**: Extract educational background with:\n",
    "   - Degree, institution, graduation year\n",
    "   - Relevant coursework or achievements\n",
    "\n",
    "10. **ATS_FEEDBACK**: Provide objective evaluation:\n",
    "    - score: 0-100 based on ATS compatibility\n",
    "    - summary: Brief assessment\n",
    "    - strengths: Positive aspects\n",
    "    - improvements: Areas for enhancement \n",
    "\n",
    "Guidelines:\n",
    "- Detect section names dynamically (e.g., \"Profile\", \"About Me\", \"Objective\" ‚Üí summary).\n",
    "- CRITICAL: Skills extraction must be source-aware:\n",
    "  * \"skills\" array: ONLY from dedicated skills sections (Skills, Technical Skills, Core Skills, Programming Languages, etc.)\n",
    "  * \"extra_skills\" array: Skills mentioned in work experience, projects, certifications, education, or other contexts\n",
    "- Extract job/project details separately.\n",
    "- Be consistent and produce clean JSON only.\n",
    "- Prioritize accuracy over completeness.\n",
    "- IMPORTANT: Return ONLY the JSON object, no additional text or explanations.\n",
    "\n",
    "Resume Text:\n",
    "{resume_text}\n",
    "\"\"\")\n",
    "\n",
    "# Build the chain with StrOutputParser for better JSON handling\n",
    "resume_parser_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    output_parser=StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57a559f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P7' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Parsing Error: Expecting value: line 1 column 1 (char 0)\n",
      "Raw output that failed to parse:\n",
      "```json\n",
      "{\n",
      "  \"name\": \"KODIPAKA SAIDIVYA\",\n",
      "  \"location\": \"India\",\n",
      "  \"summary\": \"I am a dedicated student and avid continuous learner with a strong proficiency in electrical and electronics engineering. I have gained valuable hands-on experience during a 6-month internship at a TS Transco substation. Currently, I am expanding my expertise in data science, SQL, and Python to keep pace with emerging technological advancements.\",\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"C\",\n",
      "    \"SQL\",\n",
      "    \"Data Structures\",\n",
      "    \"Data Science\",\n",
      "    \"MS Excel\",\n",
      "    \"AutoCAD\",\n",
      "    \"CMOS VLSI Design\",\n",
      "    \"Circuit Designing\",\n",
      "    \"Electronics Enthusiast\",\n",
      "    \"Electrical Proficiency\",\n",
      "    \"Quick Learning\",\n",
      "    \"problem solving\",\n",
      "    \"Adaptability\",\n",
      "    \"Leadership qualities\"\n",
      "  ],\n",
      "  \"extra_skills\": [\n",
      "    \"MATLAB\",\n",
      "    \"ML\",\n",
      "    \"Simulink\",\n",
      "    \"advanced grid technologies\",\n",
      "    \"smart grid systems\",\n",
      "    \"renewable energy sources\",\n",
      "    \"high-voltage equipment\",\n",
      "    \"system reliability\",\n",
      "    \"Hangman game development\",\n",
      "    \"chatbot development\",\n",
      "    \"EV development\",\n",
      "    \"lithium-ion battery applications\",\n",
      "    \"substation operations\",\n",
      "    \"maintenance\",\n",
      "    \"RL algorithms (Q-learning, DQN)\",\n",
      "    \"UAV autonomous navigation\",\n",
      "    \"IC 741\",\n",
      "    \"audio quality\",\n",
      "    \"signal amplification\",\n",
      "    \"controller board\",\n",
      "    \"energy efficiency\",\n",
      "    \"automation\",\n",
      "    \"Reinforcement Learning\",\n",
      "    \"AI-ML\",\n",
      "    \"Electrical and Electronics Engineering\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"job_title\": \"Python Developer (Intern)\",\n",
      "      \"company\": \"CodeAlpha India\",\n",
      "      \"duration\": \"01/06/24 ‚Äì 30/06/24\",\n",
      "      \"location\": null,\n",
      "      \"description\": [\n",
      "        \"Developed a Hangman game to enhance programming skills and problem-solving abilities.\",\n",
      "        \"Created a small chatbot to improve user interaction and automation.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"job_title\": \"Modern Power Systems Trainee\",\n",
      "      \"company\": \"Zafnish Power\",\n",
      "      \"duration\": \"05/05/24 ‚Äì 04/06/24\",\n",
      "      \"location\": null,\n",
      "      \"description\": [\n",
      "        \"Gained practical experience with advanced grid technologies and smart grid systems.\",\n",
      "        \"Worked on integrating renewable energy sources with modern power distribution networks.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"job_title\": \"EV Design & Analysis Intern\",\n",
      "      \"company\": \"National Small Scale Industries (NSIC)\",\n",
      "      \"duration\": \"09/05/23 - 31/05/23\",\n",
      "      \"location\": null,\n",
      "      \"description\": [\n",
      "        \"Applied MATLAB and Simulink for EV development, gaining hands-on experience.\",\n",
      "        \"Explored lithium-ion battery applications, enhancing EV efficiency.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"job_title\": \"Industrial Trainee\",\n",
      "      \"company\": \"TS TRANSCO (220/112)KV\",\n",
      "      \"duration\": \"01/01/22 - 31/06/22\",\n",
      "      \"location\": null,\n",
      "      \"description\": [\n",
      "        \"Acquired extensive knowledge of substation operations and maintenance.\",\n",
      "        \"Developed practical skills in handling high-voltage equipment and ensuring system reliability.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"project_name\": \"Autonomous Unmanned Aerial Vehicle Navigation Using ML\",\n",
      "      \"duration\": \"Feb 2024 ‚Äì Present\",\n",
      "      \"technologies_used\": [\n",
      "        \"ML\",\n",
      "        \"RL algorithms (Q-learning, DQN)\"\n",
      "      ],\n",
      "      \"description\": \"Implemented RL algorithms (Q-learning, DQN) for UAV autonomous navigation.\"\n",
      "    },\n",
      "    {\n",
      "      \"project_name\": \"Audio Amplifier using IC 741\",\n",
      "      \"duration\": \"Sep 2023 - Dec 2023\",\n",
      "      \"technologies_used\": [\n",
      "        \"IC 741\"\n",
      "      ],\n",
      "      \"description\": \"Designed and evaluated a headphone amplifier circuit with IC 741 to enhance audio quality and signal amplification.\"\n",
      "    },\n",
      "    {\n",
      "      \"project_name\": \"Remote Control Air Cooler\",\n",
      "      \"duration\": \"Jul 2021 - Dec 2021\",\n",
      "      \"technologies_used\": [\n",
      "        \"Controller board\"\n",
      "      ],\n",
      "      \"description\": \"Implemented Automated a home air cooler. Developed a controller board to enhance energy efficiency and automation.\"\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": [\n",
      "    {\n",
      "      \"name\": \"Certified SQL & Python\",\n",
      "      \"organization\": \"HackerRank\",\n",
      "      \"year\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Electrical AutoCAD Certified Professional\",\n",
      "      \"organization\": \"LinkedIn Learning\",\n",
      "      \"year\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Certified in Reinforcement Learning\",\n",
      "      \"organization\": \"Infosys Springboard\",\n",
      "      \"year\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"SQL & Python Certified Professional\",\n",
      "      \"organization\": \"LinkedIn Learning\",\n",
      "      \"year\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Elite Certificate in CMOS Digital VLSI Design\",\n",
      "      \"organization\": \"NPTEL\",\n",
      "      \"year\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"AI-ML Virtual Internship Completion Certificate\",\n",
      "      \"organization\": \"AICTE, EduSkills Portal\",\n",
      "      \"year\": null\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"B.TECH in Electrical and Electronics Engineering\",\n",
      "      \"institution\": \"Sreenidhi Institute of Science and Technology\",\n",
      "      \"graduation_year\": \"2022-present\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"DIPLOMA in Electrical and Electronics Engineering\",\n",
      "      \"institution\": \"SRRS Government Polytechnic\",\n",
      "      \"graduation_year\": \"2019-2022\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"SSC (Class X)\",\n",
      "      \"institution\": \"Sri Saraswathi Shishu Mandir\",\n",
      "      \"graduation_year\": \"2018-2019\"\n",
      "    }\n",
      "  ],\n",
      "  \"ats_feedback\": {\n",
      "    \"score\": 85,\n",
      "    \"summary\": \"This resume is well-structured and keyword-rich, demonstrating a strong foundation in Electrical and Electronics Engineering with a clear pivot towards Data Science and AI/ML. The use of dedicated sections for skills, work experience, and projects enhances ATS compatibility.\",\n",
      "    \"strengths\": [\n",
      "      \"Clear and concise summary highlighting key skills and career direction.\",\n",
      "      \"Well-organized sections with bullet points for responsibilities and achievements.\",\n",
      "      \"Strong technical skills section with a good mix of languages, tools, and core engineering concepts.\",\n",
      "      \"Relevant certifications that support the stated career goals.\",\n",
      "      \"Diverse work experience and projects showcasing practical application of skills.\",\n",
      "      \"Good use of keywords relevant to both electrical engineering and data science/ML.\"\n",
      "    ],\n",
      "    \"improvements\": [\n",
      "      \"Add specific city and country for each work experience entry to provide full context.\",\n",
      "      \"Quantify achievements in work experience and project descriptions where possible (e.g., 'improved efficiency by X%', 'reduced errors by Y%').\",\n",
      "      \"Specify expected graduation year for the ongoing B.Tech degree instead of '2022-present'.\",\n",
      "      \"Consider adding a professional LinkedIn profile URL directly in the contact information.\",\n",
      "      \"Ensure consistent formatting for dates (e.g., 'MM/YY' or 'Month Year').\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract text\n",
    "resume_path = \"app/resumes/SaidivyaResume.pdf\"\n",
    "text = extract_text_from_file(resume_path, \"pdf\")\n",
    "\n",
    "# Step 2: Parse with Gemini\n",
    "try:\n",
    "    raw_output = resume_parser_chain.run({\"resume_text\": text})\n",
    "    # print(\"Raw LLM Output:\")\n",
    "    # print(raw_output)\n",
    "    # print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Parse JSON from the output\n",
    "    structured_output = json.loads(raw_output)\n",
    "    print(\"Parsed JSON Output:\")\n",
    "    print(json.dumps(structured_output, indent=2))\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON Parsing Error: {e}\")\n",
    "    print(\"Raw output that failed to parse:\")\n",
    "    print(raw_output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Raw output:\")\n",
    "    print(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinkedIn API Integration for Agentic Job Scraping and Matching\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class LinkedInJobAgent:\n",
    "    \"\"\"\n",
    "    Agentic LinkedIn Job Scraping and Matching Agent\n",
    "    Uses LinkedIn Marketing API for job data and AI for intelligent matching\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, access_token: str, api_version: str = \"202312\"):\n",
    "        self.access_token = access_token\n",
    "        self.api_version = api_version\n",
    "        self.base_url = f\"https://api.linkedin.com/v{api_version}\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {access_token}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-Restli-Protocol-Version\": \"2.0.0\"\n",
    "        }\n",
    "    \n",
    "    def search_jobs_agentically(self, \n",
    "                              keywords: List[str],\n",
    "                              location: str,\n",
    "                              experience_level: str,\n",
    "                              job_type: str,\n",
    "                              max_results: int = 50) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Agentically search for jobs using LinkedIn API with intelligent filtering\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Build intelligent search query\n",
    "            search_params = self._build_intelligent_search_params(\n",
    "                keywords, location, experience_level, job_type\n",
    "            )\n",
    "            \n",
    "            # Make API request\n",
    "            response = requests.get(\n",
    "                f\"{self.base_url}/jobSearch\",\n",
    "                headers=self.headers,\n",
    "                params=search_params\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                jobs_data = response.json()\n",
    "                return self._process_job_results(jobs_data, max_results)\n",
    "            else:\n",
    "                print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in job search: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _build_intelligent_search_params(self, \n",
    "                                       keywords: List[str],\n",
    "                                       location: str,\n",
    "                                       experience_level: str,\n",
    "                                       job_type: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Build intelligent search parameters based on job requirements\n",
    "        \"\"\"\n",
    "        # Convert keywords to LinkedIn search format\n",
    "        keyword_query = \" OR \".join([f'\"{kw}\"' for kw in keywords])\n",
    "        \n",
    "        # Map experience levels to LinkedIn codes\n",
    "        experience_mapping = {\n",
    "            \"entry\": \"1\",\n",
    "            \"associate\": \"2\", \n",
    "            \"mid\": \"3\",\n",
    "            \"senior\": \"4\",\n",
    "            \"executive\": \"5\"\n",
    "        }\n",
    "        \n",
    "        # Map job types to LinkedIn codes\n",
    "        job_type_mapping = {\n",
    "            \"full-time\": \"F\",\n",
    "            \"part-time\": \"P\",\n",
    "            \"contract\": \"C\",\n",
    "            \"internship\": \"I\"\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"keywords\": keyword_query,\n",
    "            \"locationName\": location,\n",
    "            \"experienceLevel\": experience_mapping.get(experience_level, \"3\"),\n",
    "            \"jobType\": job_type_mapping.get(job_type, \"F\"),\n",
    "            \"sortBy\": \"DD\",  # Date descending\n",
    "            \"count\": 50\n",
    "        }\n",
    "    \n",
    "    def _process_job_results(self, jobs_data: Dict, max_results: int) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Process and enrich job results with additional data\n",
    "        \"\"\"\n",
    "        processed_jobs = []\n",
    "        \n",
    "        for job in jobs_data.get(\"elements\", [])[:max_results]:\n",
    "            # Extract basic job info\n",
    "            job_info = {\n",
    "                \"id\": job.get(\"id\"),\n",
    "                \"title\": job.get(\"title\"),\n",
    "                \"company\": job.get(\"companyName\"),\n",
    "                \"location\": job.get(\"location\"),\n",
    "                \"description\": job.get(\"description\"),\n",
    "                \"posted_date\": job.get(\"postedDate\"),\n",
    "                \"job_type\": job.get(\"jobType\"),\n",
    "                \"experience_level\": job.get(\"experienceLevel\"),\n",
    "                \"salary\": job.get(\"salaryInfo\"),\n",
    "                \"remote_allowed\": job.get(\"remoteAllowed\"),\n",
    "                \"skills\": job.get(\"skills\", []),\n",
    "                \"linkedin_url\": f\"https://linkedin.com/jobs/view/{job.get('id')}\"\n",
    "            }\n",
    "            \n",
    "            # Enrich with company data\n",
    "            if job.get(\"companyId\"):\n",
    "                company_data = self._get_company_info(job[\"companyId\"])\n",
    "                job_info.update(company_data)\n",
    "            \n",
    "            processed_jobs.append(job_info)\n",
    "        \n",
    "        return processed_jobs\n",
    "    \n",
    "    def _get_company_info(self, company_id: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Get additional company information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{self.base_url}/companies/{company_id}\",\n",
    "                headers=self.headers\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                company_data = response.json()\n",
    "                return {\n",
    "                    \"company_size\": company_data.get(\"companySize\"),\n",
    "                    \"industry\": company_data.get(\"industry\"),\n",
    "                    \"company_description\": company_data.get(\"description\"),\n",
    "                    \"company_website\": company_data.get(\"websiteUrl\")\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting company info: {e}\")\n",
    "        \n",
    "        return {}\n",
    "    \n",
    "    def match_jobs_with_resume(self, \n",
    "                             jobs: List[Dict], \n",
    "                             resume_data: Dict) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Agentically match jobs with resume using AI-powered analysis\n",
    "        \"\"\"\n",
    "        matched_jobs = []\n",
    "        \n",
    "        for job in jobs:\n",
    "            # Calculate match score using multiple factors\n",
    "            match_score = self._calculate_match_score(job, resume_data)\n",
    "            \n",
    "            if match_score > 0.3:  # Minimum threshold\n",
    "                job[\"match_score\"] = match_score\n",
    "                job[\"match_reasons\"] = self._get_match_reasons(job, resume_data)\n",
    "                matched_jobs.append(job)\n",
    "        \n",
    "        # Sort by match score\n",
    "        return sorted(matched_jobs, key=lambda x: x[\"match_score\"], reverse=True)\n",
    "    \n",
    "    def _calculate_match_score(self, job: Dict, resume_data: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Calculate match score between job and resume\n",
    "        \"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Skills match (40% weight)\n",
    "        job_skills = set([skill.lower() for skill in job.get(\"skills\", [])])\n",
    "        resume_skills = set([skill.lower() for skill in resume_data.get(\"skills\", [])])\n",
    "        extra_skills = set([skill.lower() for skill in resume_data.get(\"extra_skills\", [])])\n",
    "        all_resume_skills = resume_skills.union(extra_skills)\n",
    "        \n",
    "        if job_skills and all_resume_skills:\n",
    "            skills_match = len(job_skills.intersection(all_resume_skills)) / len(job_skills)\n",
    "            score += skills_match * 0.4\n",
    "        \n",
    "        # Experience level match (20% weight)\n",
    "        if job.get(\"experience_level\") and resume_data.get(\"work_experience\"):\n",
    "            exp_match = self._match_experience_level(job[\"experience_level\"], resume_data[\"work_experience\"])\n",
    "            score += exp_match * 0.2\n",
    "        \n",
    "        # Location match (15% weight)\n",
    "        if job.get(\"location\") and resume_data.get(\"location\"):\n",
    "            location_match = self._match_location(job[\"location\"], resume_data[\"location\"])\n",
    "            score += location_match * 0.15\n",
    "        \n",
    "        # Job type match (10% weight)\n",
    "        if job.get(\"job_type\"):\n",
    "            job_type_match = self._match_job_type(job[\"job_type\"], resume_data)\n",
    "            score += job_type_match * 0.1\n",
    "        \n",
    "        # Education match (15% weight)\n",
    "        if resume_data.get(\"education\"):\n",
    "            education_match = self._match_education(job, resume_data[\"education\"])\n",
    "            score += education_match * 0.15\n",
    "        \n",
    "        return min(score, 1.0)  # Cap at 1.0\n",
    "    \n",
    "    def _match_experience_level(self, job_level: str, work_experience: List[Dict]) -> float:\n",
    "        \"\"\"\n",
    "        Match experience level between job and resume\n",
    "        \"\"\"\n",
    "        # Count years of experience\n",
    "        total_years = 0\n",
    "        for exp in work_experience:\n",
    "            if exp.get(\"duration\"):\n",
    "                # Parse duration and calculate years (simplified)\n",
    "                total_years += self._parse_duration_to_years(exp[\"duration\"])\n",
    "        \n",
    "        # Map job levels to expected years\n",
    "        level_mapping = {\n",
    "            \"entry\": (0, 2),\n",
    "            \"associate\": (1, 4),\n",
    "            \"mid\": (3, 7),\n",
    "            \"senior\": (6, 12),\n",
    "            \"executive\": (10, 20)\n",
    "        }\n",
    "        \n",
    "        expected_range = level_mapping.get(job_level, (0, 5))\n",
    "        if expected_range[0] <= total_years <= expected_range[1]:\n",
    "            return 1.0\n",
    "        elif total_years < expected_range[0]:\n",
    "            return 0.5  # Underqualified but might be acceptable\n",
    "        else:\n",
    "            return 0.7  # Overqualified but still relevant\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def _match_location(self, job_location: str, resume_location: str) -> float:\n",
    "        \"\"\"\n",
    "        Match location compatibility\n",
    "        \"\"\"\n",
    "        if not job_location or not resume_location:\n",
    "            return 0.5\n",
    "        \n",
    "        job_location = job_location.lower()\n",
    "        resume_location = resume_location.lower()\n",
    "        \n",
    "        # Exact match\n",
    "        if job_location == resume_location:\n",
    "            return 1.0\n",
    "        \n",
    "        # Same city\n",
    "        job_city = job_location.split(\",\")[0].strip()\n",
    "        resume_city = resume_location.split(\",\")[0].strip()\n",
    "        if job_city == resume_city:\n",
    "            return 0.9\n",
    "        \n",
    "        # Same country\n",
    "        job_country = job_location.split(\",\")[-1].strip()\n",
    "        resume_country = resume_location.split(\",\")[-1].strip()\n",
    "        if job_country == resume_country:\n",
    "            return 0.6\n",
    "        \n",
    "        # Remote work\n",
    "        if \"remote\" in job_location:\n",
    "            return 0.8\n",
    "        \n",
    "        return 0.2\n",
    "    \n",
    "    def _match_job_type(self, job_type: str, resume_data: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Match job type preferences\n",
    "        \"\"\"\n",
    "        # This could be enhanced with user preferences\n",
    "        # For now, return neutral score\n",
    "        return 0.5\n",
    "    \n",
    "    def _match_education(self, job: Dict, education: List[Dict]) -> float:\n",
    "        \"\"\"\n",
    "        Match education requirements\n",
    "        \"\"\"\n",
    "        # This could be enhanced with specific degree requirements\n",
    "        # For now, return neutral score if education exists\n",
    "        return 0.7 if education else 0.3\n",
    "    \n",
    "    def _parse_duration_to_years(self, duration: str) -> float:\n",
    "        \"\"\"\n",
    "        Parse duration string to years (simplified)\n",
    "        \"\"\"\n",
    "        # This is a simplified parser - could be enhanced\n",
    "        if \"year\" in duration.lower():\n",
    "            return 1.0\n",
    "        elif \"month\" in duration.lower():\n",
    "            return 0.1\n",
    "        return 0.5\n",
    "    \n",
    "    def _get_match_reasons(self, job: Dict, resume_data: Dict) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get reasons why job matches resume\n",
    "        \"\"\"\n",
    "        reasons = []\n",
    "        \n",
    "        # Skills match reasons\n",
    "        job_skills = set([skill.lower() for skill in job.get(\"skills\", [])])\n",
    "        resume_skills = set([skill.lower() for skill in resume_data.get(\"skills\", [])])\n",
    "        extra_skills = set([skill.lower() for skill in resume_data.get(\"extra_skills\", [])])\n",
    "        all_resume_skills = resume_skills.union(extra_skills)\n",
    "        \n",
    "        matching_skills = job_skills.intersection(all_resume_skills)\n",
    "        if matching_skills:\n",
    "            reasons.append(f\"Skills match: {', '.join(list(matching_skills)[:3])}\")\n",
    "        \n",
    "        # Experience match\n",
    "        if job.get(\"experience_level\"):\n",
    "            reasons.append(f\"Experience level suitable: {job['experience_level']}\")\n",
    "        \n",
    "        # Location match\n",
    "        if job.get(\"location\"):\n",
    "            reasons.append(f\"Location compatible: {job['location']}\")\n",
    "        \n",
    "        return reasons\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Initialize the agent\n",
    "    access_token = \"YOUR_LINKEDIN_ACCESS_TOKEN\"\n",
    "    job_agent = LinkedInJobAgent(access_token)\n",
    "    \n",
    "    # Search for jobs\n",
    "    jobs = job_agent.search_jobs_agentically(\n",
    "        keywords=[\"python\", \"machine learning\", \"data science\"],\n",
    "        location=\"Bangalore, India\",\n",
    "        experience_level=\"mid\",\n",
    "        job_type=\"full-time\",\n",
    "        max_results=20\n",
    "    )\n",
    "    \n",
    "    # Load resume data (from your resume parser)\n",
    "    resume_data = {\n",
    "        \"name\": \"Yeswanth Yerra\",\n",
    "        \"location\": \"Chennai, India\",\n",
    "        \"skills\": [\"Python\", \"Java\", \"JavaScript\", \"Spring Boot\", \"React.js\"],\n",
    "        \"extra_skills\": [\"Machine Learning\", \"Docker\", \"AWS\", \"MongoDB\"],\n",
    "        \"work_experience\": [\n",
    "            {\n",
    "                \"job_title\": \"Full Stack Development Intern\",\n",
    "                \"company\": \"Pantech Prolabs Pvt Ltd\",\n",
    "                \"duration\": \"June 2024 - October 2024\"\n",
    "            }\n",
    "        ],\n",
    "        \"education\": [\n",
    "            {\n",
    "                \"degree\": \"Computer Science and Engineering\",\n",
    "                \"institution\": \"Some University\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Match jobs with resume\n",
    "    matched_jobs = job_agent.match_jobs_with_resume(jobs, resume_data)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Found {len(jobs)} jobs, matched {len(matched_jobs)} with resume\")\n",
    "    for job in matched_jobs[:5]:  # Top 5 matches\n",
    "        print(f\"\\nüéØ {job['title']} at {job['company']}\")\n",
    "        print(f\"   Match Score: {job['match_score']:.2f}\")\n",
    "        print(f\"   Location: {job['location']}\")\n",
    "        print(f\"   Reasons: {'; '.join(job['match_reasons'])}\")\n",
    "        print(f\"   URL: {job['linkedin_url']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration Example: LinkedIn Job Agent + Resume Parser\n",
    "def integrate_job_matching_with_resume_parser():\n",
    "    \"\"\"\n",
    "    Example of how to integrate LinkedIn Job Agent with your resume parser\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Parse resume (using your existing parser)\n",
    "    print(\"üìÑ Parsing resume...\")\n",
    "    resume_path = \"app/resumes/Yeswanth_Yerra_CV.pdf\"\n",
    "    text = extract_text_from_file(resume_path, \"pdf\")\n",
    "    \n",
    "    # Parse with your existing chain\n",
    "    raw_output = resume_parser_chain.run({\"resume_text\": text})\n",
    "    resume_data = json.loads(raw_output)\n",
    "    \n",
    "    print(f\"‚úÖ Resume parsed for: {resume_data.get('name')}\")\n",
    "    print(f\"üìç Location: {resume_data.get('location')}\")\n",
    "    print(f\"üõ†Ô∏è  Skills: {len(resume_data.get('skills', []))} main skills\")\n",
    "    print(f\"‚ûï Extra Skills: {len(resume_data.get('extra_skills', []))} additional skills\")\n",
    "    \n",
    "    # Step 2: Initialize LinkedIn Job Agent\n",
    "    print(\"\\nüîç Initializing LinkedIn Job Agent...\")\n",
    "    linkedin_token = \"YOUR_LINKEDIN_ACCESS_TOKEN\"  # You'll need to get this\n",
    "    job_agent = LinkedInJobAgent(linkedin_token)\n",
    "    \n",
    "    # Step 3: Extract search parameters from resume\n",
    "    search_keywords = []\n",
    "    search_keywords.extend(resume_data.get(\"skills\", [])[:5])  # Top 5 main skills\n",
    "    search_keywords.extend(resume_data.get(\"extra_skills\", [])[:3])  # Top 3 extra skills\n",
    "    \n",
    "    # Remove duplicates and convert to lowercase\n",
    "    search_keywords = list(set([kw.lower() for kw in search_keywords]))[:8]\n",
    "    \n",
    "    print(f\"üéØ Search keywords: {search_keywords}\")\n",
    "    \n",
    "    # Step 4: Search for jobs\n",
    "    print(\"\\nüîç Searching for jobs...\")\n",
    "    jobs = job_agent.search_jobs_agentically(\n",
    "        keywords=search_keywords,\n",
    "        location=resume_data.get(\"location\", \"India\"),\n",
    "        experience_level=\"mid\",  # Could be determined from resume\n",
    "        job_type=\"full-time\",\n",
    "        max_results=30\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Found {len(jobs)} jobs\")\n",
    "    \n",
    "    # Step 5: Match jobs with resume\n",
    "    print(\"\\nüéØ Matching jobs with resume...\")\n",
    "    matched_jobs = job_agent.match_jobs_with_resume(jobs, resume_data)\n",
    "    \n",
    "    print(f\"‚úÖ {len(matched_jobs)} jobs matched with resume\")\n",
    "    \n",
    "    # Step 6: Display top matches\n",
    "    print(\"\\nüèÜ TOP JOB MATCHES:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, job in enumerate(matched_jobs[:5], 1):\n",
    "        print(f\"\\n{i}. üéØ {job['title']} at {job['company']}\")\n",
    "        print(f\"   üìä Match Score: {job['match_score']:.2f}/1.0\")\n",
    "        print(f\"   üìç Location: {job['location']}\")\n",
    "        print(f\"   üíº Type: {job['job_type']}\")\n",
    "        print(f\"   üè¢ Industry: {job.get('industry', 'N/A')}\")\n",
    "        print(f\"   üîó URL: {job['linkedin_url']}\")\n",
    "        \n",
    "        print(f\"   ‚úÖ Match Reasons:\")\n",
    "        for reason in job['match_reasons']:\n",
    "            print(f\"      ‚Ä¢ {reason}\")\n",
    "        \n",
    "        if job.get('salary'):\n",
    "            print(f\"   üí∞ Salary: {job['salary']}\")\n",
    "    \n",
    "    return matched_jobs\n",
    "\n",
    "# LinkedIn API Setup Instructions\n",
    "def setup_linkedin_api():\n",
    "    \"\"\"\n",
    "    Instructions for setting up LinkedIn API access\n",
    "    \"\"\"\n",
    "    print(\"\"\"\n",
    "üîß LINKEDIN API SETUP INSTRUCTIONS:\n",
    "\n",
    "1. Create LinkedIn App:\n",
    "   - Go to https://www.linkedin.com/developers/apps\n",
    "   - Click \"Create app\"\n",
    "   - Fill in app details\n",
    "\n",
    "2. Request API Access:\n",
    "   - Go to \"Products\" tab\n",
    "   - Request access to \"Marketing Developer Platform\"\n",
    "   - Request access to \"Talent Solutions\" (for job data)\n",
    "\n",
    "3. Get Access Token:\n",
    "   - Use OAuth 2.0 flow to get user authorization\n",
    "   - Exchange authorization code for access token\n",
    "   - Store token securely\n",
    "\n",
    "4. API Endpoints Available:\n",
    "   - /jobSearch - Search for jobs\n",
    "   - /companies/{id} - Get company details\n",
    "   - /people/{id} - Get people profiles (if needed)\n",
    "\n",
    "5. Rate Limits:\n",
    "   - Marketing API: 500 requests per app per day\n",
    "   - Talent Solutions: Varies by plan\n",
    "\n",
    "6. Alternative Approaches:\n",
    "   - LinkedIn Learning API (for skills)\n",
    "   - Partner APIs (like Indeed, Glassdoor)\n",
    "   - Web scraping with proper rate limiting\n",
    "   \n",
    "üìù Note: LinkedIn API access requires approval and may have restrictions.\n",
    "Consider alternative job data sources if LinkedIn API is not available.\n",
    "\"\"\")\n",
    "\n",
    "# Run the integration example\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ LinkedIn Job Matching Integration Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show setup instructions\n",
    "    setup_linkedin_api()\n",
    "    \n",
    "    # Note: Uncomment below to run actual integration\n",
    "    # (requires valid LinkedIn API token)\n",
    "    # matched_jobs = integrate_job_matching_with_resume_parser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f763301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ab09c48b774dfa92fc66e14640757d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872f80de23b64ae485aaeda25e458187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8474b907f7c74ec78fc959fce2db392e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6307971d5549308100458a7299794d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eff3a78afd74a72af303da516cadacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad143724d304319bb546c497e715d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d382837658a840858c6debc232114068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf018ec28ac484a960b9bd1ec3be57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb5727639f24212bb981f71dd48acc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5f166f51ac4cd7b85e5e5d4f2cc72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e111f585b0dd4155b9bfba567d0ac399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Searching for recent 'Backend Engineer Bangalore' jobs from linkedin.com/jobs ...\n",
      "‚ö†Ô∏è Error scraping: /search?q=site:linkedin.com/jobs+Backend+Engineer+Bangalore&sca_esv=a1c6a911e61942c7&emsg=SG_REL&sei=yfjkaPqfBd6f0PEPgI28sAk | No connection adapters were found for '/search?q=site:linkedin.com/jobs+Backend+Engineer+Bangalore&sca_esv=a1c6a911e61942c7&emsg=SG_REL&sei=yfjkaPqfBd6f0PEPgI28sAk'\n",
      "No jobs found or accessible. Try another keyword.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# üìò Job Search Agent (LinkedIn/Naukri Scraper + Skill Matching)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install langchain langchain-google-genai sentence-transformers\n",
    "# pip install requests beautifulsoup4 python-dotenv\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "from typing import List, Dict\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ‚úÖ Load API Keys and Environment Variables\n",
    "# --------------------------------------------------------------\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ‚öôÔ∏è Embedding Model Setup\n",
    "# --------------------------------------------------------------\n",
    "# You can replace this with Gemini embedding endpoint later.\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_text_batch(texts: List[str]):\n",
    "    return embedding_model.encode(texts, convert_to_tensor=True, show_progress_bar=False)\n",
    "\n",
    "def embed_text(text: str):\n",
    "    return embedding_model.encode([text], convert_to_tensor=True, show_progress_bar=False)\n",
    "\n",
    "def cosine_similarity_batch(a, b):\n",
    "    return util.cos_sim(a, b)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# üßπ Utility: Check Recency\n",
    "# --------------------------------------------------------------\n",
    "RECENT_DAYS = 30\n",
    "\n",
    "def is_recent_post(date_str: str) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a job post date (like '3 days ago' or 'Posted on 05 Aug 2025')\n",
    "    is within RECENT_DAYS.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not date_str:\n",
    "            return True\n",
    "        if \"ago\" in date_str.lower():\n",
    "            m = re.search(r\"(\\d+)\\s+days?\\s+ago\", date_str)\n",
    "            if m:\n",
    "                num = int(m.group(1))\n",
    "                return num <= RECENT_DAYS\n",
    "        # Parse absolute date format like '05 Aug 2025'\n",
    "        dt = datetime.strptime(date_str, \"%d %b %Y\")\n",
    "        return (datetime.now() - dt).days <= RECENT_DAYS\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# üåê Fetch Job Links (Google site: search)\n",
    "# --------------------------------------------------------------\n",
    "def google_job_links_recent(domain: str, keyword: str, num: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Fetches recent job links using Google site search.\n",
    "    Example: site:linkedin.com/jobs Backend Engineer Bangalore\n",
    "    \"\"\"\n",
    "    search_url = f\"https://www.google.com/search?q=site:{domain}%20{keyword}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(search_url, headers=headers, timeout=10)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    links = []\n",
    "    for a in soup.select(\"a\"):\n",
    "        href = a.get(\"href\")\n",
    "        if href and domain in href:\n",
    "            m = re.match(r\"/url\\?q=(https?://[^&]+)\", href)\n",
    "            if m:\n",
    "                real = m.group(1)\n",
    "                links.append(real)\n",
    "            else:\n",
    "                links.append(href)\n",
    "\n",
    "    # Deduplicate and limit\n",
    "    unique = []\n",
    "    for l in links:\n",
    "        if l not in unique:\n",
    "            unique.append(l)\n",
    "        if len(unique) >= num:\n",
    "            break\n",
    "    return unique\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# üïµÔ∏è LinkedIn Scraper\n",
    "# --------------------------------------------------------------\n",
    "def scrape_linkedin_job(url: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Scrapes LinkedIn job page to extract job details.\n",
    "    Note: Works best with accessible job URLs (public pages).\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(url, headers=headers, timeout=10)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    title = soup.find(\"h1\", {\"class\": re.compile(r\"topcard__title\", re.IGNORECASE)})\n",
    "    title = title.get_text().strip() if title else \"\"\n",
    "\n",
    "    comp = soup.find(\"a\", {\"class\": re.compile(r\"topcard__org-name-link\", re.IGNORECASE)})\n",
    "    company = comp.get_text().strip() if comp else \"\"\n",
    "\n",
    "    loc = soup.find(\"span\", {\"class\": re.compile(r\"topcard__flavor--bullet\", re.IGNORECASE)})\n",
    "    location = loc.get_text().strip() if loc else \"\"\n",
    "\n",
    "    date_el = soup.find(\"span\", string=re.compile(r\"ago|Posted\", re.IGNORECASE))\n",
    "    posted = date_el.get_text().strip() if date_el else \"\"\n",
    "\n",
    "    desc_div = soup.find(\"div\", {\"class\": re.compile(r\"show-more-less-html__markup\", re.IGNORECASE)})\n",
    "    description = desc_div.get_text().strip() if desc_div else \"\"\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"company\": company,\n",
    "        \"location\": location,\n",
    "        \"posted\": posted,\n",
    "        \"description\": description,\n",
    "    }\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# üß† Main Agent Function\n",
    "# --------------------------------------------------------------\n",
    "def agent_fetch_and_match(keyword: str, user_profile: str, portal=\"linkedin.com/jobs\", num_jobs=5):\n",
    "    \"\"\"\n",
    "    1Ô∏è‚É£ Searches for recent jobs from LinkedIn/Naukri (via Google site search)\n",
    "    2Ô∏è‚É£ Scrapes job details\n",
    "    3Ô∏è‚É£ Filters recent jobs\n",
    "    4Ô∏è‚É£ Matches with user profile using embeddings\n",
    "    5Ô∏è‚É£ Returns ranked jobs\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Searching for recent '{keyword}' jobs from {portal} ...\")\n",
    "\n",
    "    links = google_job_links_recent(portal, keyword, num=num_jobs)\n",
    "    jobs = []\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            job = scrape_linkedin_job(link)\n",
    "            if is_recent_post(job[\"posted\"]):\n",
    "                jobs.append(job)\n",
    "            time.sleep(1)  # avoid bot detection\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è Error scraping:\", link, \"|\", e)\n",
    "\n",
    "    if not jobs:\n",
    "        print(\"No jobs found or accessible. Try another keyword.\")\n",
    "        return []\n",
    "\n",
    "    # Compute embeddings\n",
    "    texts = [f\"{j['title']} {j['description']} {j['location']}\" for j in jobs]\n",
    "    job_vecs = embed_text_batch(texts)\n",
    "    user_vec = embed_text(user_profile)\n",
    "\n",
    "    # Compute similarity\n",
    "    sims = cosine_similarity_batch(user_vec, job_vecs)[0]\n",
    "    for i, j in enumerate(jobs):\n",
    "        j[\"match_score\"] = float(sims[i])\n",
    "\n",
    "    jobs_sorted = sorted(jobs, key=lambda x: x[\"match_score\"], reverse=True)\n",
    "\n",
    "    print(f\"‚úÖ Found {len(jobs_sorted)} relevant jobs.\")\n",
    "    return jobs_sorted\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# üß™ Example Test Run\n",
    "# --------------------------------------------------------------\n",
    "user_profile = \"Python, FastAPI, Backend, AWS, SQL, Docker, REST APIs, Microservices\"\n",
    "results = agent_fetch_and_match(\"Backend Engineer Bangalore\", user_profile, portal=\"linkedin.com/jobs\", num_jobs=5)\n",
    "\n",
    "for i, job in enumerate(results[:5], 1):\n",
    "    print(f\"\\n{i}. {job['title']} - {job['company']}\")\n",
    "    print(f\"üìç {job['location']} | üïì {job['posted']}\")\n",
    "    print(f\"üí° Match Score: {job['match_score']:.2f}\")\n",
    "    print(f\"üîó {job['url']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
